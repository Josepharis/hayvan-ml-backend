import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error

# Veri setini yÃ¼kle
print("ğŸ“Š Veri seti yÃ¼kleniyor...")
df = pd.read_csv('../python_backend/gelisim_kayitlari_dataset.csv')

print(f"ğŸ”¢ Toplam kayÄ±t sayÄ±sÄ±: {len(df)}")
print(f"ğŸ“‹ Toplam sÃ¼tun sayÄ±sÄ±: {len(df.columns)}")

print("\nğŸ§ TÃœM SÃœTUNLAR VE VERÄ° TÄ°PLERÄ°:")
print("="*50)
for i, (col, dtype) in enumerate(df.dtypes.items(), 1):
    null_count = df[col].isnull().sum()
    unique_count = df[col].nunique()
    print(f"{i:2d}. {col:20s} | {str(dtype):10s} | Null: {null_count:4d} | Unique: {unique_count:4d}")

print("\nğŸ“Š Ä°LK 5 KAYIT:")
print("="*80)
print(df.head())

print("\nğŸ“ˆ NUMERÄ°K SÃœTUNLARIN Ä°STATÄ°STÄ°KLERÄ°:")
print("="*80)
numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
print(f"Numerik sÃ¼tunlar: {numeric_cols}")
print(df[numeric_cols].describe())

print("\nğŸ·ï¸ KATEGORÄ°K SÃœTUNLARIN DEÄERLERÄ°:")
print("="*80)
categorical_cols = df.select_dtypes(include=['object']).columns.tolist()
print(f"Kategorik sÃ¼tunlar: {categorical_cols}")

for col in categorical_cols:
    print(f"\n{col.upper()} deÄŸerleri:")
    print(df[col].value_counts())

# Hedef deÄŸiÅŸkeni bul
print("\nğŸ¯ HEDEF DEÄÄ°ÅKEN ANALÄ°ZÄ°:")
print("="*50)
if 'gunlukArtis' in df.columns:
    target = 'gunlukArtis' 
    print(f"Hedef deÄŸiÅŸken: {target}")
    print(f"Min: {df[target].min():.3f}")
    print(f"Max: {df[target].max():.3f}")
    print(f"Ortalama: {df[target].mean():.3f}")
    print(f"Standart sapma: {df[target].std():.3f}")
elif 'kilo' in df.columns:
    target = 'kilo'
    print(f"Alternatif hedef: {target}")
    print(f"Min: {df[target].min():.3f}")
    print(f"Max: {df[target].max():.3f}")
    print(f"Ortalama: {df[target].mean():.3f}")
    print(f"Standart sapma: {df[target].std():.3f}")
else:
    print("âŒ Hedef deÄŸiÅŸken bulunamadÄ±!")
    print("Mevcut sÃ¼tunlar:", df.columns.tolist())
    exit()

# TÃœM Ã¶zellikleri hazÄ±rla
print("\nğŸ”§ TÃœM Ã–ZELLÄ°KLER HAZIRLANÄ°YOR...")
print("="*50)

# Kopya oluÅŸtur
df_ml = df.copy()

# Kategorik deÄŸiÅŸkenleri encode et
label_encoders = {}
for col in categorical_cols:
    if col != target:  # Hedef deÄŸiÅŸken kategorik deÄŸilse
        le = LabelEncoder()
        df_ml[col] = le.fit_transform(df_ml[col].astype(str))
        label_encoders[col] = le
        print(f"âœ… {col} encoded: {len(le.classes_)} farklÄ± deÄŸer")

# Eksik deÄŸerleri doldur
print("\nğŸ”§ EKSÄ°K DEÄERLER DOLDuruluyor...")
for col in df_ml.columns:
    if df_ml[col].isnull().sum() > 0:
        if df_ml[col].dtype in ['int64', 'float64']:
            df_ml[col] = df_ml[col].fillna(df_ml[col].median())
            print(f"âœ… {col}: {df[col].isnull().sum()} eksik deÄŸer median ile dolduruldu")
        else:
            df_ml[col] = df_ml[col].fillna(df_ml[col].mode()[0])
            print(f"âœ… {col}: {df[col].isnull().sum()} eksik deÄŸer mode ile dolduruldu")

# Feature'larÄ± ve target'Ä± ayÄ±r  
print(f"\nğŸ¯ HEDEF DEÄÄ°ÅKEN: {target}")
y = df_ml[target]
X = df_ml.drop(columns=[target])

print(f"ğŸ“Š Feature sayÄ±sÄ±: {X.shape[1]}")
print(f"ğŸ“‹ Feature isimleri: {X.columns.tolist()}")

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

print(f"\nğŸ”„ TRAIN-TEST SPLIT:")
print(f"Train: {X_train.shape[0]} kayÄ±t")
print(f"Test: {X_test.shape[0]} kayÄ±t")

# Random Forest modeli - TÃœM FEATURES Ä°LE
print("\nğŸŒ² RANDOM FOREST MODELÄ° EÄÄ°TÄ°LÄ°YOR...")
print("="*50)

rf_model = RandomForestRegressor(
    n_estimators=200,        # Daha fazla aÄŸaÃ§
    max_depth=15,           # Daha derin aÄŸaÃ§lar
    min_samples_split=5,
    min_samples_leaf=2,
    random_state=42,
    n_jobs=-1              # TÃ¼m CPU core'larÄ± kullan
)

rf_model.fit(X_train, y_train)

# Tahmin ve performans
y_pred_train = rf_model.predict(X_train)
y_pred_test = rf_model.predict(X_test)

train_r2 = r2_score(y_train, y_pred_train)
test_r2 = r2_score(y_test, y_pred_test)
mae = mean_absolute_error(y_test, y_pred_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))

print(f"\nğŸ“Š MODEL PERFORMANSI:")
print("="*50)
print(f"ğŸ¯ Train RÂ²: {train_r2:.4f} ({train_r2*100:.2f}%)")
print(f"ğŸ¯ Test RÂ²: {test_r2:.4f} ({test_r2*100:.2f}%)")
print(f"ğŸ“ MAE: {mae:.4f}")
print(f"ğŸ“ RMSE: {rmse:.4f}")

# FEATURE IMPORTANCE ANALÄ°ZÄ° - TÃœM Ã–ZELLÄ°KLER
print(f"\nğŸ” FEATURE IMPORTANCE - TÃœM {len(X.columns)} Ã–ZELLÄ°K:")
print("="*60)

feature_importance = pd.DataFrame({
    'feature': X.columns,
    'importance': rf_model.feature_importances_
}).sort_values('importance', ascending=False)

print("ğŸ† Ã–NEMLÄ°LÄ°K SIRALAMASI:")
for i, (idx, row) in enumerate(feature_importance.iterrows(), 1):
    print(f"{i:2d}. {row['feature']:20s}: {row['importance']:.4f} ({row['importance']*100:.2f}%)")

# En Ã¶nemli 10 feature
top_features = feature_importance.head(10)
print(f"\nâ­ EN Ã–NEMLÄ° 10 Ã–ZELLÄ°K:")
print("="*40)
for i, (idx, row) in enumerate(top_features.iterrows(), 1):
    print(f"{i:2d}. {row['feature']:15s}: {row['importance']*100:.1f}%")

# Ã–nemsiz features (<%1)
low_importance = feature_importance[feature_importance['importance'] < 0.01]
if len(low_importance) > 0:
    print(f"\nâš ï¸  DÃœÅÃœK Ã–NEMLÄ°LÄ°KTE FEATURES (<%1):")
    print("="*40)
    for idx, row in low_importance.iterrows():
        print(f"   {row['feature']:15s}: {row['importance']*100:.2f}%")

print(f"\nğŸ“‹ Ã–ZET:")
print("="*50)
print(f"ğŸ¯ Model baÅŸarÄ±sÄ±: {test_r2*100:.1f}%")
print(f"ğŸ“Š Toplam feature: {len(X.columns)}")
print(f"â­ YÃ¼ksek Ã¶nemli (>5%): {len(feature_importance[feature_importance['importance'] > 0.05])}")
print(f"ğŸ”¸ Orta Ã¶nemli (1-5%): {len(feature_importance[(feature_importance['importance'] >= 0.01) & (feature_importance['importance'] <= 0.05)])}")
print(f"âšª DÃ¼ÅŸÃ¼k Ã¶nemli (<1%): {len(feature_importance[feature_importance['importance'] < 0.01])}")

# Model kaydet
import joblib
print(f"\nğŸ’¾ MODEL KAYDEDILIYOR...")
joblib.dump(rf_model, 'comprehensive_random_forest_model.pkl')
joblib.dump(label_encoders, 'label_encoders.pkl')
joblib.dump(X.columns.tolist(), 'feature_columns.pkl')

print("âœ… Model dosyalarÄ± kaydedildi:")
print("   - comprehensive_random_forest_model.pkl")
print("   - label_encoders.pkl") 
print("   - feature_columns.pkl")

print(f"\nğŸ‰ ANALÄ°Z TAMAMLANDI!")
print(f"ğŸš€ {test_r2*100:.1f}% doÄŸrulukla TÃœM {len(X.columns)} Ã¶zellik kullanÄ±lÄ±yor!") 